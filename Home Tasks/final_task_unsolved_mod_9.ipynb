{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_task_unsolved_mod_9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/delhian/NLP_course/blob/master/Home%20Tasks/final_task_unsolved_mod_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P13OapCzIwT"
      },
      "source": [
        "## Постановка задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-NCaT9b-lQA"
      },
      "source": [
        "В рамках данного финального задания мы посторим сеть для перевода с немецкого языка на английский."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlPQCXQf9zwT"
      },
      "source": [
        "*Этот блокнот основан на [реализации с открытым исходным кодом](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb) модели seq2seq NMT в PyTorch.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ9Lx1I3-ybs"
      },
      "source": [
        "Мы попробуем реализовать модель из этой статьи -> [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215).\n",
        "\n",
        "Модель будет обучена переводу с немецкого на английский, но ее можно применить к любой проблеме, связанной с переходом от одной последовательности к другой, например, к обобщению."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZFfVYKu_KfH"
      },
      "source": [
        "Наиболее распространенными моделями последовательностей (seq2seq) являются модели *энкодер-декодер*, которые (обычно) используют *рекуррентную нейронную сеть* (RNN) для *кодирования* исходного (входного) предложения в один вектор. В этом ноутбуке мы будем называть этот единственный вектор *контекстным вектором*. Вы можете рассматривать вектор контекста как абстрактное представление всего входного предложения. Этот вектор затем *декодируется* вторым RNN, который учится выводить целевое (выходное) предложение, генерируя его по одному слову за раз."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GwZM6Ep_XUZ"
      },
      "source": [
        "![](https://github.com/neychev/made_nlp_course/blob/master/week06_SelfAttention_and_NMT_practice/img/seq2seq1.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYH--4k_w44"
      },
      "source": [
        "!pip install https://download.pytorch.org/whl/nightly/cu102/torch-1.8.0.dev20210210-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install torchtext==0.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ZlxYkLC20f"
      },
      "source": [
        "!python -m spacy download en > /dev/null\n",
        "!python -m spacy download de > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7140amzT9qCM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import io\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import spacy\n",
        "\n",
        "from collections import Counter\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mII7kLtZ40Nz"
      },
      "source": [
        "Зафиксируем все возможные случайные сиды, для максимальной воспроизводимости"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmlStWex_pvX"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgBRyR5nBflE"
      },
      "source": [
        "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
        "train_urls = ('train.de.gz', 'train.en.gz')\n",
        "val_urls = ('val.de.gz', 'val.en.gz')\n",
        "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RVdE7fNBi34"
      },
      "source": [
        "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "droT9QIi4_Ss"
      },
      "source": [
        "Проинициализируем токенизаторы для исходного и целевого языка:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY-2-Ph0Cybp"
      },
      "source": [
        "de_tokenizer = get_tokenizer('spacy', language='de')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my53nYHOBwFI"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Напишите функцию по созданию словаря, возвращающую словарь из `torchtext`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOm4WygbCLHI"
      },
      "source": [
        "def build_vocab(filepath, tokenizer):\n",
        "  # YOUR CODE HERE\n",
        "  # return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCb6xpkiCM0l"
      },
      "source": [
        "de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyQF0RwPDbzb"
      },
      "source": [
        "Проверка функции:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkD87GFyEoAX"
      },
      "source": [
        "assert en_vocab['a'] < 10\n",
        "assert de_vocab['Ein'] < 15000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K30E1uWT5PgQ"
      },
      "source": [
        "Напишем функцию для составления большого тензора, который будет хранить на каждой строчке исходное токенизированное предложение и целевое."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cwm-wy3DbKi"
      },
      "source": [
        "def data_process(filepaths):\n",
        "  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
        "    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
        "                            dtype=torch.long)\n",
        "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
        "                            dtype=torch.long)\n",
        "    data.append((de_tensor_, en_tensor_))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sV7nGzsFMSC"
      },
      "source": [
        "Проинициализируйте переменные `train_data, val_data, test_data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWhM0WZNFdXJ"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "train_data = None\n",
        "val_data = None\n",
        "test_data = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpToqCEyFjwd"
      },
      "source": [
        "assert len(train_data) == 29000\n",
        "assert len(val_data) == 1014\n",
        "assert len(test_data) == 1000\n",
        "assert train_data[23][0].sum().item() > 3220"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35zSx-HlGfhn"
      },
      "source": [
        "#YOUR CODE HERE\n",
        "\n",
        "device = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jY4bt_CGkj0"
      },
      "source": [
        "assert device is not None\n",
        "assert device.type == 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btfg-D1aGyQy"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "PAD_IDX = de_vocab['<pad>']\n",
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VoleUx4G1G1"
      },
      "source": [
        "Дополните функцию `generate_batch` чтобы она добавляла паддинг в конце и чтобы первыми символами были `BOS_IDX`, а последним `EOS_IDX`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkwmSw6HYL-"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  de_batch, en_batch = [], []\n",
        "  for (de_item, en_item) in data_batch:\n",
        "    de_batch.append(torch.cat([torch.tensor(# insert your code, dim=0))\n",
        "    en_batch.append(torch.cat([torch.tensor(# insert your code, dim=0))\n",
        "  de_batch = # insert your code\n",
        "  en_batch = # insert your code\n",
        "  return de_batch, en_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QABYiLrGJFf"
      },
      "source": [
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "                       shuffle=True, collate_fn=generate_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F9WdPUPHuDO"
      },
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9CZqwEm8kgR"
      },
      "source": [
        "## Подготовка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ5FSyXU503R"
      },
      "source": [
        "Наконец мы переходим к написанию самой нейросети. Она будет состоять из 3 различных классов, а финальная сеть будет состоять из этих трех классов. Получится несколько объемно, но когда мы начинаем переходить к более серьезным сетям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNK-ORW1In6y"
      },
      "source": [
        "Создадим модель Seq2Seq на основе GRU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JekezzB5I0_O"
      },
      "source": [
        "Создайте класс `Encoder`, который состоит из слоя Embedding, GRU(bidirectional) и Linear:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvvpXnXcIxNT"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Your code here\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = # your code here\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:],\n",
        "                                               hidden[-1,:,:]),\n",
        "                                               dim = 1)))\n",
        "\n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9QCQDhkJUZy"
      },
      "source": [
        "Оставим класс Attention, чтобы сохранить преемственность с оригинальной статьей. Подбробнее про Attention мы поговорим в следующих модулях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRCJw2w1Iv5Y"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RdFhl6KJvB9"
      },
      "source": [
        "Добавим класс `Decoder`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7WCAa7YJyg2"
      },
      "source": [
        "Аналогично классу `Encoder` сделайте класс `Decoder` таким же по архитектуре, однако линейный слой будет иметь размерность emb_dim  плюс размерность выходного слоя Attention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-tKFwoKCIp"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = # YOUR CODE HERE\n",
        "\n",
        "        self.rnn = # YOUR CODE HERE\n",
        "\n",
        "        self.out = # YOUR CODE HERE\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "steO_DGUKxu_"
      },
      "source": [
        "Наконец, объединим все в класс модели `Seq2Seq`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8yAxyZiK4t4"
      },
      "source": [
        "Напишите, что должен принимать на вход класс Seq2Seq и проинициализируйте экземпляр этого класса:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ict3MDeKxOj"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = # YOUR CODE HERE\n",
        "        self.decoder = # YOUR CODE HERE\n",
        "        self.device = # YOUR CODE HERE\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-FbdHsi6uFC"
      },
      "source": [
        "Вы можете попробовать тут свои значения для разных слоев. Единственное - правильно задайте размеры входных слоев для Encoder и Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXUquwEVLI4m"
      },
      "source": [
        "INPUT_DIM = # YOUR CODE HERE\n",
        "OUTPUT_DIM = # YOUR CODE HERE\n",
        "ENC_EMB_DIM = 64\n",
        "DEC_EMB_DIM = 64\n",
        "ENC_HID_DIM = 128\n",
        "DEC_HID_DIM = 128\n",
        "ATTN_DIM = 32\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3bwd5mWLnMC"
      },
      "source": [
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sxA2jKgLxu2"
      },
      "source": [
        "Напишите функцию, считающую параметры модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khvc3_qgL8P4"
      },
      "source": [
        "def count_parameters(model: nn.Module):\n",
        "    return # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR5jUX5LMEQt"
      },
      "source": [
        "assert count_parameters(model) > 7_000_000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ots0k0mMMSJo"
      },
      "source": [
        "Проинициализируем веса, как это рекомендуют в оригинальной статье:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs8cWMvnJdSD"
      },
      "source": [
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-wKKaoDJdMY"
      },
      "source": [
        "PAD_IDX = en_vocab.stoi['<pad>']\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfBl6-DF8yUZ"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzSjMJYffi21"
      },
      "source": [
        "Напишите функцию обучения модели. Если получится, добавьте в тренировочный цикл запись значений функции потерь и перплексии в tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ-0BmNgf1YA"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float, \n",
        "          writer=None):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPC0UqNO7PSE"
      },
      "source": [
        "Напишем функцию для валидации модели. Хочу отметить, что при валидации наиболее важным моментом является выключение метода teacher-forcing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs7FWIJ-MgfW"
      },
      "source": [
        "def evaluate(model: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICUCceM6M047"
      },
      "source": [
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjmAW7RiM0xW"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPC8pElfI-2"
      },
      "source": [
        "Добейтесь перплексии на валидационной выборке порядка 35-40. Попробуйте различные значения параметров сети и learning rate."
      ]
    }
  ]
}