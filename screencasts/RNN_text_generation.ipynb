{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "RNN_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/delhian/NLP_course/blob/master/screencasts/RNN_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbmDhqxteX1z"
      },
      "source": [
        "Давайте попробуем сгенерировать немного шекспировской поэзии, используя знакомые нам RNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4oJAUVHeX11"
      },
      "source": [
        "### Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjkf67kCeX14"
      },
      "source": [
        "Шекспировские соннеты доступны по [этой](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger) ссылке. Также сохраним их в файл."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WUXlUl0eX15"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwCEUyTCeX2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74869e89-2c5f-4849-9c07-8d2982ea5d7b"
      },
      "source": [
        "try:\n",
        "    with open('../../datasets/Shakespeare_sonnets/sonnets.txt', 'r') as iofile:\n",
        "        text = iofile.readlines()\n",
        "except FileNotFoundError:\n",
        "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Shakespeare_sonnets/sonnets.txt -nc\n",
        "    with open('sonnets.txt', 'r') as iofile:\n",
        "        text = iofile.readlines()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-14 16:50:35--  https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Shakespeare_sonnets/sonnets.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119747 (117K) [text/plain]\n",
            "Saving to: ‘sonnets.txt’\n",
            "\n",
            "sonnets.txt         100%[===================>] 116.94K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-10-14 16:50:35 (4.53 MB/s) - ‘sonnets.txt’ saved [119747/119747]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXG-wUNTNnrL"
      },
      "source": [
        "Сделаем небольшую предобработку текста:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO3OTw-heX2H"
      },
      "source": [
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "text = ''.join(text).lower()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ORYTIweX2Q"
      },
      "source": [
        "tokens = sorted(set(text))\n",
        "vocab_size = len(tokens)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvjshgHEeX2T"
      },
      "source": [
        "token_to_idx = {char: idx for idx, char in enumerate(tokens)}\n",
        "idx_to_token = {idx: char for idx, char in token_to_idx.items()}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj-nytR9eX2Z"
      },
      "source": [
        "# Создание простой модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BrHDSTOmiUO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_fTdBPHfJz"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cERJtjD7Nrle"
      },
      "source": [
        "Напишем класс с vanilla RNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBFPty8PU7Mz"
      },
      "source": [
        "class RNNCell(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_tokens=len(tokens),\n",
        "               embedding_size=32,\n",
        "               rnn_num_units=64):\n",
        "    super(RNNCell,self).__init__()\n",
        "    self.num_units = rnn_num_units\n",
        "\n",
        "    self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "    self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
        "    self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "    \n",
        "  def forward(self, x, h_prev):\n",
        "    x_emb = self.embedding(x)\n",
        "    h_prev = h_prev.to(device)\n",
        "    x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
        "    h_next = self.rnn_update(x_and_h)\n",
        "    h_next = torch.tanh(h_next)\n",
        "\n",
        "    assert h_next.size() == h_prev.size()\n",
        "\n",
        "    logits = self.rnn_to_logits(h_next)\n",
        "    logits = F.log_softmax(logits, -1)\n",
        "\n",
        "    return h_next, logits\n",
        "\n",
        "  def initial_state(self, batch_size):\n",
        "    return torch.zeros(batch_size, self.num_units, requires_grad=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJQXfTaIOE30"
      },
      "source": [
        "Используем функцию потерь Negative log likelihood (NLL)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4R_3f9YFu1z"
      },
      "source": [
        "model = RNNCell()\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2_sFggZOPxe"
      },
      "source": [
        "Для учета предыдущего контекста и правильной начальной инициализации мы построчно пробегаем по приходящей матрице и создаем матрицу вероятностей для следующих символов. Это и делает rnn_loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jysO9Nn4AFvZ"
      },
      "source": [
        "def rnn_loop(rnn_model, batch_ix):\n",
        "  batch_size = batch_ix.size()[0]\n",
        "  hid_state = rnn_model.initial_state(batch_size)\n",
        "  logprobs = []\n",
        "\n",
        "  for x_t in batch_ix.transpose(0,1):\n",
        "    hid_state, logp_next = rnn_model(x_t, hid_state)\n",
        "    logprobs.append(logp_next)\n",
        "  \n",
        "  return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXimuZZbOTIY"
      },
      "source": [
        "Так как мы занимаемся посимвольной генерацией то нам нужна для обучения матрица со смещением на один символ вправо. Это создает функция to_matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsYDSNhrVBMc"
      },
      "source": [
        "def to_matrix(words, seq_length=16, dtype='int32', batch_first = True):\n",
        "  if len(words) > seq_length:\n",
        "    seq_length = len(words) - 1 \n",
        "\n",
        "  words_ix = np.zeros((len(words) - seq_length, seq_length), dtype) # matrix for 1 char shifted sequences\n",
        "\n",
        "  for i in range(len(words) - seq_length):\n",
        "    words_ix[i, :] = [token_to_idx[c] for c in words[i:i+seq_length]]\n",
        "\n",
        "  if not batch_first: # convert [batch, time] into [time, batch]\n",
        "    words_ix = np.transpose(words_ix)\n",
        "\n",
        "  return words_ix"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ego0n9ea6rbR"
      },
      "source": [
        "batch_ix = to_matrix(text[:6], seq_length=5)\n",
        "batch_ix = torch.tensor(batch_ix, dtype=torch.int64).to(device)\n",
        "logp_seq = rnn_loop(model.to(device), batch_ix)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVesuDNfp5Zh"
      },
      "source": [
        "predictions_logp = logp_seq[:, :-1]\n",
        "actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "loss = criterion(predictions_logp.contiguous().view(-1, vocab_size), \n",
        "                  actual_next_tokens.contiguous().view(-1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKxA5NHup5Ud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8754ff9a-09d9-4216-bc97-82163d566d2e"
      },
      "source": [
        "loss.backward()\n",
        "loss"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.6267, device='cuda:0', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY2Yqzp6s885"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "from tqdm import notebook\n",
        "\n",
        "model = RNNCell()\n",
        "criterion = nn.NLLLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "history = []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goUdlfKuBX9K"
      },
      "source": [
        "# Тренировка RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUq9iLU5Of7j"
      },
      "source": [
        "Если мы посмотрим на получившуюся кривую лосс функции, то можно заметить, что она похожа на идеальную кривую обучения, без признаков к серьезному переобучению.\n",
        "\n",
        "Размер батча у нас будет равен 128 — это длина куска текста, на котором мы будем обучать нашу сеть. MAX_LENGTH — длина последовательности для генерации текста. При обучении она нам не важна и величина окна равна 32 — мы будем пробегать по 32 символам для создания матрицы смещений символов.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHBH-0c60X1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a48bc8c9-3568-4352-b8e9-4aee8efefe16"
      },
      "source": [
        "STEP = 128 # some type of minibatch\n",
        "MAX_LENGTH = 64\n",
        "WINDOW = 32\n",
        "model = model.to(device)\n",
        "\n",
        "for i in range(25):\n",
        "  for j in range(len(text) // STEP):\n",
        "    \n",
        "    batch_ix = to_matrix(text[j * STEP: (j + 1) * STEP], WINDOW)\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64).to(device)\n",
        "\n",
        "    logp_seq = rnn_loop(model, batch_ix)\n",
        "\n",
        "    # compute loss\n",
        "    predictions_logp = logp_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    loss = criterion(\n",
        "        predictions_logp.contiguous().view(-1, vocab_size),\n",
        "        actual_next_tokens.contiguous().view(-1)\n",
        "    ) \n",
        "    \n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "  history.append(loss.item())\n",
        "  if (i+1)%1==0:\n",
        "      clear_output(True)\n",
        "      plt.plot(history,label='loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_pZ3q6VOvlL"
      },
      "source": [
        "Функция ниже генерирует текст по фразе длиной не менее SEQ_LENGTH."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCVi0_B3O8-V"
      },
      "source": [
        "Важным параметром при генерации является температура. Ее можно представить как некое подобие энтропии — меры неопределенности системы. Чем она выше, тем хаотичнее сэмплирование. \n",
        "\n",
        "Обратите внимание: модель возвращает вероятности символов, а не сами символы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czG_z9RCQHeB"
      },
      "source": [
        "def generate_sample(char_rnn, seed_phrase=' hello', length=MAX_LENGTH, temperature=1.0):\n",
        "    result = [token_to_idx[token] for token in seed_phrase]\n",
        "\n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1).to(device)\n",
        "    \n",
        "    # начало генерации\n",
        "    for i in range(length):\n",
        "        hid_state, logs_p = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        p_next = F.softmax(logs_p / temperature, dim=-1).to('cpu').data[0].numpy()\n",
        "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
        "        result.append(next_ix)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)[:, 1:]\n",
        "    return ''.join([tokens[ix] for ix in result])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tBJOG_fA172"
      },
      "source": [
        "print(generate_sample(model.to(device), \n",
        "                      seed_phrase=' hello', \n",
        "                      length=223, \n",
        "                      temperature=0.75))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9i1NOY6eX2l"
      },
      "source": [
        "# Более поэтичная модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUvCzVqoPKB6"
      },
      "source": [
        "Перейдем к более продвинутой модели, использующей GRU-блоки. Мы будем использовать самую простую однонаправленную сеть с одним уровнем рекуррентных блоков. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdDR_vjDVB3Y"
      },
      "source": [
        "WINDOW = 800\n",
        "\n",
        "EPOCHS = 1050\n",
        "LEARNING_RATE = 0.005\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 100\n",
        "NUM_HIDDEN = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNos0VsWIHK5"
      },
      "source": [
        "## Предобработка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0kLSs_YVLMn"
      },
      "source": [
        "tokens = sorted(set(text))\n",
        "vocab_size = len(tokens)\n",
        "\n",
        "token_to_idx = {char: idx for idx, char in enumerate(tokens)}\n",
        "idx_to_token = {idx: char for char, idx in token_to_idx.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDz9fIvIPIJR"
      },
      "source": [
        "def string_to_matrix(words):\n",
        "    result = [token_to_idx[char] for char in words]\n",
        "    result = torch.tensor(result, dtype=torch.long)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEYZ2CsUVIiw"
      },
      "source": [
        "def sample_text(text):\n",
        "    start = np.random.randint(0, len(text) - WINDOW) + 1\n",
        "    int_text = string_to_matrix(text[start:start + WINDOW + 1])\n",
        "    inputs = int_text[:-1]\n",
        "    outputs = int_text[1:]\n",
        "    return inputs, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZKYNXk7Pb3b"
      },
      "source": [
        "## Модель с GRU-блоком"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1AYxFMRVQxa"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size=vocab_size,\n",
        "              output_size=vocab_size,   \n",
        "              embed_size=EMBEDDING_DIM,\n",
        "              hidden_size=HIDDEN_DIM,\n",
        "              num_layers=NUM_HIDDEN):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.gru = nn.GRU(input_size=embed_size,\n",
        "                          hidden_size=hidden_size,\n",
        "                          num_layers=num_layers)\n",
        "        self.dence = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.init_hidden = torch.nn.Parameter(torch.zeros(\n",
        "                                              num_layers, 1, hidden_size))\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embed = self.embedding(x.view(1, -1))\n",
        "        output, hidden =  self.gru(embed.view(1, 1, -1), hidden)\n",
        "        output = self.dence(output.view(1, -1))\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_zero_state(self):\n",
        "        init_hidden = torch.zeros(self.num_layers, 1, self.hidden_size).to(device)\n",
        "        return init_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oatKef83jZWC"
      },
      "source": [
        "model = GRU(num_layers=1)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLwdXJn6PpNE"
      },
      "source": [
        "Обучим нашу модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5SxjIs2pPOR"
      },
      "source": [
        "history = []\n",
        "for i in range(750):\n",
        "\n",
        "    ### FORWARD AND BACK PROP\n",
        "\n",
        "    hidden = model.init_zero_state().to(device)\n",
        "    \n",
        "    loss = 0.\n",
        "    inputs, targets = sample_text(text)\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    for c in range(WINDOW):\n",
        "        outputs, hidden = model(inputs[c], hidden)\n",
        "        loss += F.nll_loss(outputs, targets[c].view(1))\n",
        "\n",
        "    loss /= WINDOW\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    history.append(loss.item())\n",
        "    if (i+1)%50==0:\n",
        "      clear_output(True)\n",
        "      plt.plot(history,label='loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb1AUzltPsZr"
      },
      "source": [
        "На сей раз GRU обучается чуть быстрее. Это связано с тем, что мы использовали более быстрый проход по тексту скользящим окном. Потому мы получили не такую пологую функцию потерь на кривой обучения. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EazRO28qKpCG"
      },
      "source": [
        "def predict(model, seed_sequence, length=100, temperature=0.75):\n",
        "    hidden = model.init_zero_state().to(device)\n",
        "    given_input = string_to_matrix(seed_sequence).to(device)\n",
        "    predicted = seed_sequence\n",
        "\n",
        "    for i in range(len(seed_sequence) - 1):\n",
        "        _, hidden = model(given_input[i], hidden)\n",
        "    inp = given_input[-1].to(device)\n",
        "    \n",
        "    for p in range(length):\n",
        "        output, hidden = model(inp, hidden)\n",
        "        \n",
        "        output = output.detach().cpu()\n",
        "        output_dist = F.softmax(output / temperature, dim=-1).to('cpu').data[0].numpy()\n",
        "        next_char = np.random.choice(len(tokens), p=output_dist)\n",
        "        \n",
        "        predicted_char = idx_to_token[next_char]\n",
        "        predicted += predicted_char\n",
        "        inp = string_to_matrix(predicted_char).to(device)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHcPT6S0Ic_O"
      },
      "source": [
        "print(predict(model, ' hello', 500, 0.65))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GTBxEqNPx1B"
      },
      "source": [
        "Посмотрим, что получается при различных значениях температуры. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aUasb5q8mCl"
      },
      "source": [
        "for temp in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
        "  print(predict(model, ' hello', 500, temp), end=f\"\\nsample for temperature -> {temp}\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk8c7_oeP4L6"
      },
      "source": [
        "На сей раз GRU-четко уловила структуру текста, и даже проскакивает рифма в придуманном моделью тексте. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7__IL_ojQubC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}