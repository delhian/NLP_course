{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/delhian/NLP_course/blob/master/screencasts/transformers_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8mjClFLQMCy"
      },
      "source": [
        "# Загрузка датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-w4lumQPLR"
      },
      "source": [
        "Загрузим файл с датасетом и посмотрим, какие тексты он содержит. Скачать файл вы можете на учебной платформе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3rl2fgQu-U"
      },
      "source": [
        "В качестве данных для начала фразы мы будем использовать небольшую выборку из твитов твиттер-канала “Усы Пескова”. Берутся 7 произвольных твитов, разделенных специальным знаком, и на основе этого текста тренированная модель дописывает продолжения. \n",
        "\n",
        "\n",
        "Как и в предыдущем примере с использованием RNN, одним из важных параметров является температура. Однако, тут также есть ряд других настраиваемых параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhbWf5sW5HvT"
      },
      "source": [
        "!pip install transformers > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ct4v4CnITlc",
        "outputId": "24da08b9-7008-45ce-bc97-598d43440aa2"
      },
      "source": [
        "with open('tweets.txt', 'r') as f:\n",
        "    tweets = f.read().strip().split('\\n\\n')\n",
        "print(len(tweets))\n",
        "for i in range(3):\n",
        "    print(tweets[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n",
            "Соловьев наконец-то вышел на новый уровень - теперь его стали банить и в офлайне\n",
            "Дарим мы тебе бутылку игристого вина. Пить тебе еще рано, но встретиться с ней за некоторые преступления ты уже можешь. ПОЗ-ДРАВ-ЛЯ-ЕМ!\n",
            "Да. Еще очень многие помнят, что такое госплан, как планировалось, талоны на еду, очереди, дефицит, выездные визы. Но спасибо, что напомнил\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORTnKsVNIZvN",
        "outputId": "df0546e8-c797-4a9c-ae07-f63bb47be445"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEg1Y-CFIpqr"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaFUfCCfQc1Y"
      },
      "source": [
        "# Загрузка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTPbjhD9QfXl"
      },
      "source": [
        "Рассмотрим генерацию текста с использованием предобученных моделей. Ранее мы рассмотрели, что их есть небольшое количество, даже для русского языка. \n",
        "\n",
        "В рамках этого ноутбука будет использоваться самая маленькая нейросеть ruGPT-3 small на основе GPT-2, тренировавшаяся на корпусах текста русского языка. Эта модель является авторегрессионной, то есть она учитывает только контекст слева при генерации продолжения текста.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgqSZnM4IvBa",
        "outputId": "3db450d6-cced-4e31-9bd9-b0a440ceeb22"
      },
      "source": [
        "model_name = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR-54kNsRFpk"
      },
      "source": [
        "# Генерация текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTDp40EmIxaZ"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OESVotdJQ-TF"
      },
      "source": [
        "Возьмем произвольные твиты, на которых будет тренироваться модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jFO-lM4I2Ag",
        "outputId": "268090e5-b5b3-4772-e6b6-1f40fdf665e5"
      },
      "source": [
        "sep = '\\n***\\n'\n",
        "\n",
        "prefix = sep.join([''] + random.sample(tweets, k=7) + [''])\n",
        "\n",
        "tokens = tokenizer(prefix, return_tensors='pt')\n",
        "tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
        "end_token_id = tokenizer.encode('*')[0]\n",
        "print(prefix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "***\n",
            "Видимо, чтобы проголосовать онлайн, нужно будет прийти на участок с паспортом, зарегистрироваться в журнале участковой комиссии и удобно проголосовать не в кабинке, а на компьютере\n",
            "***\n",
            "Знаете, это тот случай, когда Россия может на 400% доверять своему партнеру\n",
            "***\n",
            "Ну, с Михалковым все понятно. А для тех, кто тоже не различает понятия “Кооператив Озеро” и “Россия” еще раз напомним, что санкции предлагается вводить не против России, а против окружения Владимира Владимировича\n",
            "***\n",
            "Ну это примерно как Пескову поручить расследовать информацию о его часах\n",
            "***\n",
            "Роскомнадзор - Федеральная служба по надзору за попаданием Владимира Соловьева в тренды Ютуба и комнаты Клабхауса\n",
            "***\n",
            "Дети, всем, кто был на уроке за ОМОН, по физкультуре - автоматы!\n",
            "***\n",
            "Ну всё. Теперь придется господствовать\n",
            "***\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D63YKhVGQ5uN"
      },
      "source": [
        "Посмотрим, что генерирует модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qa7IgJYI5NI",
        "outputId": "64a0fcc2-fa5b-4964-fe7a-9861848d137a"
      },
      "source": [
        "size = tokens['input_ids'].shape[1]\n",
        "output = model.generate(\n",
        "    **tokens, \n",
        "    do_sample=True, \n",
        "    max_length=size+128, \n",
        "    repetition_penalty=1.2, \n",
        "    temperature=0.5,\n",
        "    num_beams=1,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "decoded = tokenizer.decode(output[0])\n",
        "result = decoded[len(prefix):]\n",
        "print('\\n', result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Я вот думаю: если бы у Путина были права, он мог бы сделать так же?\n",
            "***\n",
            "Как-то мне кажется, что Путин должен быть более сдержанным в оценке своих действий. Как минимум, со стороны государства. Ведь мы живем во время холодной войны. И даже если вдруг случится ядерное столкновение или война, то тогда можно будет сказать Путину спасибо, что он не стал президентом и не пошел на войну (хотя бы потому, что ему было интересно). Но ведь нельзя говорить об этом вслух...\n",
            "\n",
            "\n",
            "33581923\tmaximkamaxov\t2018-02-03 03:42:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBLRSIF-RMRu"
      },
      "source": [
        "# Чат-бот"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEiL6RrTROMt"
      },
      "source": [
        "Одно из самых удивительных применений такой модели является то, что можно достаточно лаконично встроить ее и создать разговорный чат-бот, который будет придумывать ответы, опираясь на ваш предыдущий контекст разговора."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRXR6J4CI_Hv"
      },
      "source": [
        "def respond_to_dialog(texts):\n",
        "    prefix = '\\nx:'\n",
        "    for i, t in enumerate(texts):\n",
        "        prefix += t\n",
        "        prefix += '\\nx:' if i % 2 == 1 else '\\ny:'\n",
        "    tokens = tokenizer(prefix, return_tensors='pt')\n",
        "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
        "    end_token_id = tokenizer.encode('\\n')[0]\n",
        "    size = tokens['input_ids'].shape[1]\n",
        "    output = model.generate(\n",
        "        **tokens, \n",
        "        eos_token_id=end_token_id,\n",
        "        do_sample=True, \n",
        "        max_length=size+128, \n",
        "        repetition_penalty=3.2, \n",
        "        temperature=1,\n",
        "        num_beams=3,\n",
        "        length_penalty=0.01,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    decoded = tokenizer.decode(output[0])\n",
        "    result = decoded[len(prefix):]\n",
        "    return result.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "EBocLnkPJjiD",
        "outputId": "f4470dc7-393f-42ba-b186-cccfc9dfbe0d"
      },
      "source": [
        "seed = input('Начните диалог с ботом любой фразой\\n')\n",
        "history = [seed]\n",
        "while True:\n",
        "    result = respond_to_dialog(history[-10:])\n",
        "    next_sentence = input(result + '\\n')\n",
        "    history.append(result)\n",
        "    history.append(next_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начните диалог с ботом любой фразой\n",
            "Как сам?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Примерно так.\n",
            "как вот так?\n",
            "Так же, как и в предыдущем примере.\n",
            "ты очень скучный\n",
            "Я просто не умею делать то, что я хочу\n",
            "заставили?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-47a92521e7b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrespond_to_dialog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnext_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr3bNyYrJkEW",
        "outputId": "75a4d93d-b686-4ee6-ab00-90aba285171f"
      },
      "source": [
        "for i in range(10):\n",
        "    print(respond_to_dialog(['Давай поговорим о домашних животных', 'Каких питомцев вы любите?\\n--------', \n",
        "                             'Давай поговорим о машинах', 'Какого цвета твой автомобиль?\\n--------',\n",
        "                             'Давай поговорим о физике']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Как ты относишься к технике?\n",
            "Как ты думаешь, что будет если в один прекрасный день все люди будут ездить на велосипедах?\n",
            "Как ты относишься к математике?\n",
            "Какое у тебя хобби?\n",
            "Какое животное ты любишь?\n",
            "Как ты думаешь, какой у тебя компьютер?\n",
            "А что это такое?\n",
            "Как ты думаешь, сколько раз в неделю нужно ходить на тренировку?\n",
            "Какое у тебя хобби?\n",
            "А как ты относишься к химии?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgZC92HLPI_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}